{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87158fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "range_resolution = 0.0214\n",
    "n_angle_bins = 64\n",
    "POWER_THRESH = 1e2\n",
    "\n",
    "RUNS = [\n",
    "    #sit\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Sitting\\Run1-SmallRoomAverageNoise\\OriginalRunIQ.csv\", \"sit\",100,66),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Sitting\\Run2-Lab\\OriginalRunIQ.csv\",  \"sit\",100,166),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Sitting\\run3bed\\run3sit.csv\", \"sit\",0,66),\n",
    "    #stand\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Standing\\StandingRun1SmallRoom\\Original.csv\",  \"stand\",260,326),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Standing\\StandingRun2CompLab\\stand2run.csv\", \"stand\",100,166),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Standing\\standrun3bedroom\\run3bed.csv\",  \"stand\",0,66),\n",
    "    #lying\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Lying\\Run1-SmallRoomCouch\\Original.csv\",  \"lying\",420,486),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Lying\\run2chairLab\\run2lab.csv\", \"lying\",60,126),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Lying\\run3bed\\run3lying.csv\",  \"lying\",0,66),\n",
    "    #walk\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Walking\\WalkingRun1SmallRoom\\Original.csv\",  \"walk\",100,166),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Walking\\walkingrun2-lab\\walk2.csv\", \"walk\",10,76),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Walking\\walk3run\\walk3bed.csv\",  \"walk\",0,66),\n",
    "    #fall\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Falling\\FallingRun1SmallLivingRoomToCouch\\Original.csv\",  \"fall\",100,166),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Falling\\fallingLab2\\fall2lab.csv\", \"fall\",20,86),\n",
    "    (r\"C:\\Users\\USER\\Desktop\\DataCollection\\Falling\\fall3bed\\bedfall3.csv\",  \"fall\",0,66)\n",
    "]\n",
    "\n",
    "SAVE_DIR_XYZ = r\"C:\\Users\\USER\\precomputed_pointclouds\\xyz\"           \n",
    "SAVE_DIR_MAG = r\"C:\\Users\\USER\\precomputed_pointclouds\\magnitude\"\n",
    "os.makedirs(SAVE_DIR_XYZ, exist_ok=True)\n",
    "os.makedirs(SAVE_DIR_MAG, exist_ok=True)\n",
    "\n",
    "def _unique_path(base_dir, base_name):\n",
    "    path = os.path.join(base_dir, base_name)\n",
    "    counter = 2\n",
    "    while os.path.exists(path):\n",
    "        root, ext = os.path.splitext(base_name)\n",
    "        base_name = f\"{root}({counter}){ext}\"\n",
    "        path = os.path.join(base_dir, base_name)\n",
    "        counter += 1\n",
    "    return path\n",
    "\n",
    "def _range_fft_and_points(df, num_frames_to_keep=66, with_intensity=False):\n",
    "    #frame number handling + taking middle 66 frames\n",
    "    unique_frames = sorted(df[\"frame\"].unique())\n",
    "    total_frames = len(unique_frames)\n",
    "\n",
    "    if total_frames < num_frames_to_keep:\n",
    "        print(f\"[WARN] CSV only has {total_frames} frames (< {num_frames_to_keep}) — keeping all.\")\n",
    "        frames_to_use = unique_frames\n",
    "    else:\n",
    "        mid_start = (total_frames - num_frames_to_keep) // 2\n",
    "        frames_to_use = unique_frames[mid_start: mid_start + num_frames_to_keep]\n",
    "\n",
    "    df = df[df[\"frame\"].isin(frames_to_use)]\n",
    "\n",
    "    #reindex frames\n",
    "    frame_map = {old: new for new, old in enumerate(sorted(df[\"frame\"].unique()))}\n",
    "    df[\"frame\"] = df[\"frame\"].map(frame_map)\n",
    "\n",
    "    n_frames  = int(df[\"frame\"].max()) + 1\n",
    "    n_rx      = int(df[\"rx\"].max()) + 1\n",
    "    n_chirps  = int(df[\"chirp\"].max()) + 1\n",
    "    n_samples = int(df[\"sample\"].max()) + 1\n",
    "\n",
    "    pointclouds = []\n",
    "    sin_axis = np.linspace(-1, 1, n_angle_bins, dtype=np.float32)#compute sin axis for Angle of Arrival\n",
    "\n",
    "    #process each frame\n",
    "    for f in range(n_frames):\n",
    "        fdf = df[df[\"frame\"] == f]\n",
    "        frame_data = np.zeros((n_rx, n_samples, n_chirps), dtype=np.complex64)\n",
    "\n",
    "        # fast vectorized fill\n",
    "        rr  = fdf[\"rx\"].to_numpy(np.int64)\n",
    "        ss  = fdf[\"sample\"].to_numpy(np.int64)\n",
    "        cc  = fdf[\"chirp\"].to_numpy(np.int64)\n",
    "        vals = fdf[\"I\"].to_numpy(np.float32) + 1j * fdf[\"Q\"].to_numpy(np.float32) if \"I\" in fdf.columns else fdf[\"ival\"].to_numpy(np.float32) + 1j * fdf[\"qval\"].to_numpy(np.float32)\n",
    "        frame_data[rr, ss, cc] = vals\n",
    "\n",
    "        #apply hanning window and range fft\n",
    "        window = np.hanning(n_samples).astype(np.float32)\n",
    "        windowed = frame_data * window[:, None]\n",
    "        range_fft = np.fft.fft(windowed, axis=1)[:, : n_samples // 2, :]\n",
    "\n",
    "        #building points\n",
    "        pts = []\n",
    "        for r in range(range_fft.shape[1]):\n",
    "            rng = r * range_resolution\n",
    "            for d in range(range_fft.shape[2]):\n",
    "                signal = range_fft[:, r, d]\n",
    "                if np.abs(signal).max() < POWER_THRESH or n_rx < 3: #thresholding\n",
    "                    continue\n",
    "\n",
    "                rx1, rx2, rx3 = signal[0], signal[1], signal[2]\n",
    "\n",
    "                #applying azmuith and elevation transformations using 3 recieving antennas\n",
    "                az_signal = np.array([rx2, rx1], dtype=np.complex64)\n",
    "                az_fft = np.fft.fftshift(np.fft.fft(az_signal, n=n_angle_bins))\n",
    "                az_idx = int(np.argmax(np.abs(az_fft)))\n",
    "                sin_theta = float(np.clip(sin_axis[az_idx], -1.0, 1.0))\n",
    "                theta = np.arcsin(sin_theta)\n",
    "\n",
    "                el_signal = np.array([rx2, rx3], dtype=np.complex64)\n",
    "                el_fft = np.fft.fftshift(np.fft.fft(el_signal, n=n_angle_bins))\n",
    "                el_idx = int(np.argmax(np.abs(el_fft)))\n",
    "                sin_phi = float(np.clip(sin_axis[el_idx], -1.0, 1.0))\n",
    "                phi = np.arcsin(sin_phi)\n",
    "\n",
    "                #converting polar coords to cartesian x,y,z\n",
    "                x = rng * np.cos(phi) * np.sin(theta)\n",
    "                y = rng * np.cos(phi) * np.cos(theta)\n",
    "                z = rng * np.sin(phi)\n",
    "\n",
    "                if with_intensity:\n",
    "                    mag = float(np.abs(signal).max())\n",
    "                    pts.append((x, y, z, mag))\n",
    "                else:\n",
    "                    pts.append((x, y, z))\n",
    "\n",
    "        if with_intensity:\n",
    "            pointclouds.append(np.array(pts, dtype=np.float32) if pts else np.zeros((0, 4), dtype=np.float32))\n",
    "        else:\n",
    "            pointclouds.append(np.array(pts, dtype=np.float32) if pts else np.zeros((0, 3), dtype=np.float32))\n",
    "\n",
    "    return pointclouds, total_frames\n",
    "\n",
    "def read_and_filter_pointclouds_xyz(path, num_frames_to_keep=66):\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"CSV not found: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    #rename cols\n",
    "    df = df.rename(columns={\n",
    "        \"Frame Index\": \"frame\",\n",
    "        \"Chirp Index\": \"chirp\",\n",
    "        \"Sample Index\": \"sample\",\n",
    "        \"Antenna Index\": \"rx\",\n",
    "        \"I\": \"ival\",\n",
    "        \"Q\": \"qval\"\n",
    "    })\n",
    "\n",
    "    #ensure all cols are numeric\n",
    "    for col in [\"frame\", \"chirp\", \"sample\", \"rx\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"raise\").astype(int)\n",
    "    for col in [\"ival\", \"qval\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"raise\").astype(np.float32)\n",
    "\n",
    "    pcs, total_frames = _range_fft_and_points(df, num_frames_to_keep=num_frames_to_keep, with_intensity=False)\n",
    "    print(f\"[INFO] {path}: kept {len(pcs)} frames out of {total_frames} total.\")\n",
    "    return pcs\n",
    "\n",
    "def read_and_filter_pointclouds_mag(path, num_frames_to_keep=66):\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"CSV not found: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path).rename(columns={\n",
    "        \"Frame Index\": \"frame\",\n",
    "        \"Chirp Index\": \"chirp\",\n",
    "        \"Sample Index\": \"sample\",\n",
    "        \"Antenna Index\": \"rx\",\n",
    "        \"I\": \"ival\",\n",
    "        \"Q\": \"qval\"\n",
    "    })\n",
    "\n",
    "    # Types\n",
    "    for col in [\"frame\", \"chirp\", \"sample\", \"rx\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"raise\").astype(int)\n",
    "    for col in [\"ival\", \"qval\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"raise\").astype(np.float32)\n",
    "\n",
    "    pcs, total_frames = _range_fft_and_points(df, num_frames_to_keep=num_frames_to_keep, with_intensity=True)\n",
    "    print(f\"[INFO] {os.path.basename(path)}: kept {len(pcs)} frames of {total_frames}\")\n",
    "    return pcs  #list of (Ni, 4): [x,y,z,intensity]\n",
    "\n",
    "#Processing and saving all runs (XYZ-only)\n",
    "for path, label, _, _ in RUNS:  \n",
    "    stem = os.path.splitext(os.path.basename(path))[0]\n",
    "    parent = os.path.basename(os.path.dirname(path))\n",
    "    pcs = read_and_filter_pointclouds_xyz(path, num_frames_to_keep=66)\n",
    "\n",
    "    save_name = f\"{parent}_{stem}_{label}_{len(pcs)}frames.npz\"\n",
    "    save_path = _unique_path(SAVE_DIR_XYZ, save_name)\n",
    "\n",
    "    pcs_obj = np.array(pcs, dtype=object)  # ragged list → object array\n",
    "    np.savez_compressed(save_path, pcs=pcs_obj, label=label, n_frames=len(pcs))\n",
    "    print(f\"[SAVED xyz] {label}: {len(pcs)} frames → {save_path}\")\n",
    "\n",
    "####repeat process including magnitude alongside each x,y,z pair\n",
    "\n",
    "#loop to stop as n=4, with magnitude as feature\n",
    "for path, label, _, _ in RUNS:\n",
    "    parent = os.path.basename(os.path.dirname(path))\n",
    "    stem = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "    pcs = read_and_filter_pointclouds_mag(path, num_frames_to_keep=66)  # list of (Ni,4)\n",
    "\n",
    "    save_name = f\"{parent}_{stem}_{label}_{len(pcs)}frames_intensity.npz\"\n",
    "    save_path = _unique_path(SAVE_DIR_MAG, save_name)\n",
    "\n",
    "    pcs_obj = np.array(pcs, dtype=object)\n",
    "    np.savez_compressed(\n",
    "        save_path,\n",
    "        pcs=pcs_obj,         \n",
    "        label=label,\n",
    "        n_frames=len(pcs),\n",
    "        has_intensity=True,   #magnitude flag\n",
    "        cols=np.array([\"x\",\"y\",\"z\",\"intensity\"])\n",
    "    )\n",
    "    print(f\"[SAVED mag] {label}: {len(pcs)} frames → {save_path}\")\n",
    "\n",
    "\n",
    "    \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _clean_mag_pc(pc):\n",
    "  \n",
    "    if pc is None:\n",
    "        return np.zeros((0,4), dtype=np.float32)\n",
    "    arr = np.asarray(pc)\n",
    "    #handling n=3, padding if nomag present\n",
    "    if arr.ndim == 1:\n",
    "        arr = np.atleast_2d(arr)\n",
    "    if arr.shape[1] == 3:\n",
    "        arr = np.column_stack([arr, np.zeros((arr.shape[0],), dtype=arr.dtype)])\n",
    "    if arr.ndim != 2 or arr.shape[1] != 4:\n",
    "        return np.zeros((0,4), dtype=np.float32)\n",
    "    arr = arr.astype(np.float32, copy=False)\n",
    "    mask = np.isfinite(arr).all(axis=1)\n",
    "    arr = arr[mask]\n",
    "    return arr\n",
    "\n",
    "#handling of extreme outliers distorting colour scale\n",
    "def _percentile_clip(values, low=1, high=99):\n",
    "    if values.size == 0:\n",
    "        return 0.0, 1.0\n",
    "    vmin = float(np.percentile(values, low))\n",
    "    vmax = float(np.percentile(values, high))\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax) or vmin == vmax:\n",
    "        vmax = vmin + 1.0\n",
    "    return vmin, vmax\n",
    "\n",
    "\n",
    "#plotting num_frames from npz file for visualisation\n",
    "def plot_magnitude_pointclouds(npz_path, num_frames=5, min_points=10, thresh_pkd=None, seed=0, save_png_dir=None):\n",
    "    d = np.load(npz_path, allow_pickle=True)\n",
    "    pcs = list(d[\"pcs\"])\n",
    "    label = str(d[\"label\"]) if \"label\" in d.files else \"unknown\"\n",
    "\n",
    "    cleaned = []\n",
    "    for i, pc in enumerate(pcs):\n",
    "        arr = _clean_mag_pc(pc)\n",
    "\n",
    "        #Apply threshold\n",
    "        if thresh_pkd is not None:\n",
    "            arr = arr[arr[:, 3] >= thresh_pkd]\n",
    "\n",
    "        if arr.shape[0] >= min_points:\n",
    "            cleaned.append((i, arr))\n",
    "\n",
    "    if not cleaned:\n",
    "        print(f\"[WARN] No valid frames (≥{min_points} pts) in {os.path.basename(npz_path)}\")\n",
    "        return\n",
    "\n",
    "    random.seed(seed)\n",
    "    sample = random.sample(cleaned, k=min(num_frames, len(cleaned)))\n",
    "\n",
    "    #creating a shared axis cube for more consistent viewing\n",
    "    all_pts = np.vstack([arr[:, :3] for _, arr in sample])\n",
    "    mins = all_pts.min(axis=0); maxs = all_pts.max(axis=0)\n",
    "    center = (mins + maxs) / 2.0\n",
    "    span = float(np.max(maxs - mins)) or 1.0\n",
    "\n",
    "    #saving plots\n",
    "    if save_png_dir:\n",
    "        os.makedirs(save_png_dir, exist_ok=True)\n",
    "\n",
    "    for idx, arr in sample:\n",
    "        x, y, z, mag = arr[:,0], arr[:,1], arr[:,2], arr[:,3]\n",
    "        vmin, vmax = _percentile_clip(mag, 2, 98)  # robust color limits\n",
    "\n",
    "        fig = plt.figure(figsize=(6,5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        sc = ax.scatter(x, y, z, c=mag, s=4, vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{os.path.basename(npz_path)} | Frame {idx} | {label}\")\n",
    "        ax.set_xlabel(\"X (m)\"); ax.set_ylabel(\"Y (m)\"); ax.set_zlabel(\"Z (m)\")\n",
    "        ax.set_xlim(center[0]-span/2, center[0]+span/2)\n",
    "        ax.set_ylim(center[1]-span/2, center[1]+span/2)\n",
    "        ax.set_zlim(center[2]-span/2, center[2]+span/2)\n",
    "        cbar = plt.colorbar(sc, ax=ax)\n",
    "        cbar.set_label(\"Magnitude\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if save_png_dir:\n",
    "            out_name = f\"{os.path.splitext(os.path.basename(npz_path))[0]}_frame{idx}.png\"\n",
    "            out_path = os.path.join(save_png_dir, out_name)\n",
    "            plt.savefig(out_path, dpi=200)\n",
    "            plt.close(fig)\n",
    "            print(f\"[PLOT SAVED] {out_path}\")\n",
    "        else:\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
